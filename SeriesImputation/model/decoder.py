from black import out
import torch 
import torch.nn as nn
import numpy 
import pytorch_lightning as pl
from .mlpbase import MlpModel
from .mpnn import MessagePassGates
from .gru import MpGruUnit
from einops import rearrange

class FillerOperator(nn.Module):
    def __init__(self,
                input_sizes,
                output_sizes):
        self.yvalue_linear=nn.Linear(input_sizes,output_sizes)
    
    def forward(self,X,H,M):
        """X shape:[Nt,d]
        M shape:[Nt,d]
        H shape:[Nt,h] h may equal to d
        """
        Y1=self.yvalue_linear(H)
        X1=M*X+(torch.ones(*M.shape)-M)*Y1

class Decoder(nn.Module):
    def __init__(self,
                input_sizes,
                output_sizes,
                final_hidden_size=128
    ):
        self.first_filler=FillerOperator(input_sizes,
                                        output_sizes)
        #TODO:here need another mp layer instead this form, which should be realized by torch-geometric
        self.mp_layer=MessagePassGates(input_sizes,output_sizes)
        self.linear_layer=nn.Linear(2*input_sizes+final_hidden_size,output_sizes)

    def forward(self,X,H,M):
        """
       X is the input series in time t with shape of [batch_size,Nt,d]
       H is the last hidden representation at time t-1 with shape of [batch_size,Nt,h],where h may be 128 in final state
       M is the mask for missing value with shape of [batch_size,Nt,d]

       output:X2 is generated by Xt and Ht-1 and is the embedding for Ht generation
        """
        X1=self.first_filler(X)
        embedding=torch.cat((X1,M,H),dim=2)
        S=self.mp_layer(embedding)
        embedding2=torch.cat((S,H,M))
        X2=self.linear_layer(embedding2)
        return X2

class SpatialDecoder(nn.Module):
    def __init__(self, d_in, d_model, d_out, support_len, order=1, attention_block=False, nheads=2, dropout=0.):
        super(SpatialDecoder, self).__init__()
        self.order = order
        self.lin_in = nn.Conv1d(d_in, d_model, kernel_size=1)
        self.graph_conv = MessagePassGates(c_in=d_model, c_out=d_model,
                                            support_len=support_len * order, order=1, include_self=False)
        self.register_parameter('spatial_att', None)
        self.lin_out = nn.Conv1d(2 * d_model, d_model, kernel_size=1)
        self.read_out = nn.Conv1d(2 * d_model, d_out, kernel_size=1)
        self.activation = nn.PReLU()
        self.adj = None

    def forward(self, x, m, h, u, adj, cached_support=False):
        # [batch, channels, nodes]
        x_in = [x, m, h] if u is None else [x, m, u, h]
        x_in = torch.cat(x_in, 1)
        if self.order > 1:
            if cached_support and (self.adj is not None):
                adj = self.adj
            else:
                adj = MessagePassGates.compute_support_orderK(adj, self.order, include_self=False, device=x_in.device)
                self.adj = adj if cached_support else None

        x_in = self.lin_in(x_in)
        out = self.graph_conv(x_in, adj)
        if self.spatial_att is not None:
            # [batch, channels, nodes] -> [batch, steps, nodes, features]
            x_in = rearrange(x_in, 'b f n -> b 1 n f')
            out_att = self.spatial_att(x_in, torch.eye(x_in.size(2), dtype=torch.bool, device=x_in.device))
            out_att = rearrange(out_att, 'b s n f -> b f (n s)')
            out = torch.cat([out, out_att], 1)
        out = torch.cat([out, h], 1)
        out = self.activation(self.lin_out(out))
        # out = self.lin_out(out)
        out = torch.cat([out, h], 1)
        return self.read_out(out), out